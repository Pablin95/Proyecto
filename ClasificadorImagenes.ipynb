{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  C:\\Users\\jmendoza.TECOPESCA\\OneDrive - TECNICA Y COMERCIO DE LA PESCA C.A. TECOPESCA\\Documentos\\GitHub\\Proyecto\\sportimages\\\n",
      "C:\\Users\\jmendoza.TECOPESCA\\OneDrive - TECNICA Y COMERCIO DE LA PESCA C.A. TECOPESCA\\Documentos\\GitHub\\Proyecto\\sportimages\\sportimages\\basket 1\n",
      "C:\\Users\\jmendoza.TECOPESCA\\OneDrive - TECNICA Y COMERCIO DE LA PESCA C.A. TECOPESCA\\Documentos\\GitHub\\Proyecto\\sportimages\\sportimages\\golf 1855\n",
      "Directorios leidos: 2\n",
      "Imagenes en cada directorio [1856, 9767]\n",
      "suma Total de imagenes en subdirs: 11623\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.join(os.getcwd(), 'sportimages')\n",
    "imgpath = dirname + os.sep \n",
    " \n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    " \n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    " \n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant=cant+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images.append(image)\n",
    "            b = \"Leyendo...\" + str(cant)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant)\n",
    "                prevRoot=root\n",
    "                directories.append(root)\n",
    "                dircount.append(cant)\n",
    "                cant=0\n",
    "dircount.append(cant)\n",
    " \n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas prueba texto creadas Cinthy:  11623\n",
      "0 basket\n",
      "1 golf\n",
      "Total número de salidas :  2\n",
      "Output classes :  [0 1]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
    " \n",
    "deportes=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    deportes.append(name[len(name)-1])\n",
    "    indice=indice+1\n",
    " \n",
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    " \n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total número de salidas : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (9298, 21, 28, 3) (9298,)\n",
      "Testing data shape :  (2325, 21, 28, 3) (2325,)\n",
      "Original label: 1\n",
      "After conversion to one-hot: [0. 1.]\n",
      "(7438, 21, 28, 3) (1860, 21, 28, 3) (7438, 2) (1860, 2)\n"
     ]
    }
   ],
   "source": [
    "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)\n",
    " \n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    " \n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    " \n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    " \n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)\n",
    " \n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 6\n",
    "batch_size = 64\n",
    "\n",
    "sport_model = Sequential()\n",
    "sport_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(21,28,3)))\n",
    "sport_model.add(LeakyReLU(alpha=0.1))\n",
    "sport_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "sport_model.add(Dropout(0.5))\n",
    "\n",
    "sport_model.add(Flatten())\n",
    "sport_model.add(Dense(32, activation='linear'))\n",
    "sport_model.add(LeakyReLU(alpha=0.1))\n",
    "sport_model.add(Dropout(0.5)) \n",
    "sport_model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "sport_model.summary()\n",
    "\n",
    "sport_model.compile(loss=tensorflow.keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sport_train_dropout \u001b[38;5;241m=\u001b[39m \u001b[43msport_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalid_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sport_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msports_mnist.h5py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tfProyectoTrat\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1105\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Legacy graph support is contained in `training_v1.Model`.\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m version_utils\u001b[38;5;241m.\u001b[39mdisallow_legacy_graph(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1105\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_compile_was_called\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1107\u001b[0m _disallow_inside_tf_function(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tfProyectoTrat\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2693\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   2688\u001b[0m   \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[0;32m   2689\u001b[0m   \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[0;32m   2690\u001b[0m   \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[0;32m   2691\u001b[0m   \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[0;32m   2692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[1;32m-> 2693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2694\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2695\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "sport_train_dropout = sport_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    " \n",
    "# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\n",
    "sport_model.save(\"sports_mnist.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = sport_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    " \n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
